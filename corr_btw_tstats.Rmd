---
title: "Evalauting correlation between t-statistics"
subtitle: 'Sub-sampling data'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Decorrelate}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---


<!--- 

cd /Users/gabrielhoffman/workspace/repos/heivr_analysis

cd ~/work/heivr_analysis
ml git
R

system("git pull"); rmarkdown::render("corr_btw_tstats.Rmd");



https://hoffmg01.u.hpc.mssm.edu/work/heivr_analysis/corr_btw_tstats.html

scp sklar1:~/www/work/heivr_analysis/corr_btw_tstats.html .


--->

  


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  cache = TRUE,
  package.startup.message = FALSE,
  cache.lazy = FALSE)
```

```{r load.packages, cache=FALSE}
library(MASS)
library(ggplot2)
library(Rfast)
library(variancePartition)
library(tidyverse)
library(broom)
library(heivr)
library(BiocParallel)
# library(deming)
# library(mcr)
library(parallel)
library(PRROC)
```

```{r test}
heivr.boot.se = function(x, y, v.x, v.y, nboot=1000, tol=1e-4){

  stopifnot( length(x) == length(y))
  
  ## bootstrap out
  bs.out <- replicate(nboot, {
    i <- sample.int(length(x), length(x), replace=TRUE)
    heivr(x[i], y[i], v.x[i], v.y[i], tol=tol)$rho
  })
  sd(bs.out)
}
```



```{r sims.function, cache=FALSE}
run_simulation = function(nmax, ngenes, cor.target, nvalues, hsq, nreps=100, BPPARAM=SnowParam()){

  # simulate fixed covariate
  info = data.frame(x = rnorm(nmax))
  rownames(info) = paste0("s", 1:nmax)

  # simulate coefficients
  if( cor.target == 1 ){
    beta = rnorm(ngenes, 3)
    Beta = cbind(beta, beta)
  }else{
    # Sigma = diag(1,2)
    Sigma = diag(c(5,1.4))
    Sigma[1,2] = cor.target * prod(sqrt(diag(Sigma)))
    Sigma[2,1] = Sigma[1,2]
    Beta = rmvnorm(ngenes, c(1,-1.5), Sigma)
  }
  rownames(Beta) = paste0("gene_", 1:nrow(Beta))

  # Simulate gene expression
  ##########################
  # dataset 1
  Eta1 = t(sapply(Beta[,1], function(b){
    eta = info$x*b 

    # set cor(y, eta)^2 = hsq
    # se = sqrt((1-hsq) / hsq * var(eta))
    # eta + rnorm(nmax, 0, se)
    eta
    }))
  colnames(Eta1) = paste0("s", 1:nmax)

  # dataset 2
  Eta2 = t(sapply(Beta[,2], function(b){
    eta = info$x*b 

    # set cor(y, eta)^2 = hsq
    # se = sqrt((1-hsq) / hsq * var(eta))
    # eta + rnorm(nmax, 0, se)
    eta
    }))
  colnames(Eta2) = paste0("s", 1:nmax)

  # Simulate errors
  #################

  geneExpr1 = matrix(NA, nrow(Eta1), ncol(Eta1))
  geneExpr2 = matrix(NA, nrow(Eta2), ncol(Eta2))

  rho = 0.9
  for(j in seq(nrow(Eta1)) ){
    se1 = sqrt((1-hsq) / hsq * var(Eta1[j,]))
    se2 = sqrt((1-hsq) / hsq * var(Eta2[j,]))

    # Error covariante
    S = matrix(c(se1^2, rho*se1*se2, rho*se1*se2, se2^2), 2, 2)
    Error = rmvnorm(nmax, c(0,0), S)

    geneExpr1[j,] = Eta1[j,] + Error[,1]
    geneExpr2[j,] = Eta2[j,] + Error[,2]
  }


  grd = expand.grid(k = 1:nreps, N = nvalues)

  df = bplapply(apply(grd, 1, as.list), function(x, geneExpr1, geneExpr2, info){

    suppressPackageStartupMessages({
    library(heivr)
    library(variancePartition)})
    RhpcBLASctl::omp_set_num_threads(1)

    N = x$N

    # subset data, fit regression models, and extract results
    idx1 = sample.int(nmax, N, replace=FALSE)
    fit1 = dream(geneExpr1[,idx1], ~ x, info[idx1,,drop=FALSE], quiet=TRUE)
    fit1 = eBayes(fit1)
    tab1 = topTable(fit1, coef="x", number=Inf, sort.by='none')

    # independent sample
    # idx2 = sample.int(nmax, N, replace=FALSE)
    idx2 = idx1 # same set of samples
    fit2 = dream(geneExpr2[,idx2], ~ x, info[idx2,,drop=FALSE], quiet=TRUE)
    fit2 = eBayes(fit2)
    tab2 = topTable(fit2, coef="x", number=Inf, sort.by='none')

    # merge and compute correlation between t-stats
    tab = merge(tab1, tab2, by="row.names")

    rm(fit1, tab1, fit2, tab2)

    # v = sapply(1:nrow(Eta1), function(j)
    #  cor(geneExpr1[j,idx1], geneExpr2[j,idx2]))
    # hist(v)

    # heivr - mom
    hobj.mom = with(tab, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2, (logFC.y/t.y)^2, method="mom", nboot=0 ))

    # heivr
    hobj = with(tab, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2,(logFC.y/t.y)^2, LRT=FALSE))    
    
    # covariance  
    data.frame( cor = with(tab, cor(logFC.x, logFC.y)),
                cor.mom = hobj.mom$rho,
                cor.heivr = hobj$rho,
                N = N)
  }, geneExpr1 = geneExpr1, geneExpr2 = geneExpr2, info = info, BPPARAM = BPPARAM)
  df = do.call(rbind, df)
  
  # combine results
  rbind(data.frame(Method = "heivr", 
                  cor = df$cor.heivr,  
                  N = df$N), 
        data.frame(Method = "MOM", 
                  cor = df$cor.mom, 
                  N = df$N), 
        data.frame(Method = "Pearson", 
                  cor = df$cor, 
                  N = df$N))
}
```

```{r run.sims, cache=FALSE}
# simulation parameters
nmax = 1000
ngenes = 1000
cor.target = .8
nvalues = c(5, seq(10, 40, by=10), seq(50, 100, by=30))#, seq(150, 200, by=50))
hsq = 0.6
  
# df_param = expand.grid(hsq = c(0.05, 0.10, 0.2), 
#             cor.target = c(-0.95, -0.6, -0.3, 0, 0.3, 0.6, .95))

df_param = expand.grid(hsq = c( 0.10), 
            cor.target = c(0))

df = lapply( 1:nrow(df_param), function(i){
  message(i, ':')
   
  df = run_simulation(nmax, ngenes, cor.target = df_param$cor.target[i], nvalues, hsq = df_param$hsq[i], nreps=20, BPPARAM=SnowParam(36))
  df$cor.target = df_param$cor.target[i]
  df$hsq = df_param$hsq[i]
  df  
})  
df = do.call(rbind, df)
```







```{r plot1, cache=FALSE, fig.height=20, fig.width=12}
col = c(heivr = "red3", Pearson = "blue3", MOM="green3")

df2 = df %>% 
    group_by(Method, cor.target, hsq, N) %>%
    summarize(rho.mean = mean(cor), rho.se = sd(cor))

df2$offset = sapply(df2$Method, function(x) 
                switch(x, heivr = -3, Pearson=0, MOM=3))

nmax = 1.03*(max(df2$N) + 2)
ggplot(df2, aes(N + offset, pmax(-1, pmin(1, rho.mean)), col=Method)) +
  geom_hline(aes(yintercept=cor.target), linetype="dashed", color="black") +
  geom_errorbar(aes(ymin = pmax(-1,rho.mean - 1.96*rho.se), ymax = pmin(1, rho.mean + 1.96*rho.se)), width=0) +
  geom_point() +
  geom_line() +
  theme_classic() +
  theme(aspect.ratio=1) +
  scale_y_continuous(limits=c(-1,1), expand=c(0,0.03)) +
  scale_x_continuous(limits=c(0,nmax), expand=c(0,0.03)) +
  ylab("Estimated correlation") +
  xlab("Sample size") +
  scale_color_manual(values = col) + 
  facet_grid(cor.target ~ hsq)
```

## Single plot
```{r single.plot, cache=FALSE}
 df2 %>%
  filter(hsq == 0.1, cor.target==0.95) %>%
  ggplot(aes(x=N + offset, y=pmax(-1, pmin(1, rho.mean)), col=Method)) +
  geom_hline(aes(yintercept=cor.target), linetype="dashed", color="black") +
  geom_errorbar(aes(ymin = pmax(-1,rho.mean - 1.96*rho.se), ymax = pmin(1, rho.mean + 1.96*rho.se)), width=0) +
  geom_point() +
  geom_line() +
  theme_classic() +
  theme(aspect.ratio=1) +
  scale_y_continuous(limits=c(0,1), expand=c(0,0.03)) +
  scale_x_continuous(limits=c(0,nmax), expand=c(0,0.03)) +
  ylab("Estimated correlation") +
  xlab("Sample size") +
  scale_color_manual(values = col) 
```

Simulate two datasets with `r nmax` samples and `r format(ngenes, scientific=FALSE, big.mark=',')` genes where the logFC between datasets have a correlation of `r unique(df$cor.target)`.  Perform analysis on random subsets of the data, and evaluate the correlation between the estimated t-statistics.  For each gene, the variable of interest explains `r 100*unique(df$hsq)`% of the variance.

Method of moments error is simple and fast, but is not bounded between 0 and 1.  This is mostly a problem when measurement error is large.  Also, the MOM estimater has larger sampling variance than the MLE does. 

Cite Fuller (1987) on measurement error and MOM.  Deming proposes way to estimate coefficients, but not correlation.

Attentuation bias, or regression dilution. Originally recognized by Spearman (1904) [The proof and measurement of association between two things]

Suprizingly, the convergence rate of Pearson depends on the target correlation value

Convergance time is directly related to measurement error

Prefer MLE since it generally produces lower standard error, and gives a likelihood ratio test to test for association.



show iterations determiend by meansurement error
For small error, convergnces to Pearson corr
test of association

```{r time.vs.noise}
p = 10000
set.seed(1)
Sigma = matrix(c(10, 3, 3, 4),2,2)
data = rmvnorm(p, c(0, 0), Sigma)
x = data[,1]
y = data[,2]
v = rgamma(p,10, 10)

RhpcBLASctl::omp_set_num_threads(1)
 
df = lapply(seq(-3, 3, length.out=20), function(value){
  message(value)

  res = system.time(hobj <- heivr(x, y, v*10^value, v*10^value))
  data.frame(value, 
    niter = hobj$niter, 
    logLik = hobj$logLik, 
    time = res[3])
  })
df = do.call(rbind, df)
```


```{r plot.time.vs.noise, cache=FALSE}
fig1 = ggplot(df, aes(value, niter)) +
  geom_point() +
  theme_classic() +
  theme(aspect.ratio=1) +
  xlab(bquote(log[10]~noise~variance)) +
  ylab("# iterations") +
  scale_y_log10()

fig2 = ggplot(df, aes(value, time)) +
  geom_point() +
  theme_classic() + 
  theme(aspect.ratio=1) +
  xlab(bquote(log[10]~noise~variance)) +
  ylab("Run time (seconds)") 

cowplot::plot_grid(fig1, fig2)  
```

# Test of association
heivr only out performs Pearson correlation when there is heteroskedastic noise
```{r assoc}
cor.target = .8

p = 1000
alpha = .08

nsims = 2000

df = mclapply(1:nsims, function(i){

  message(i)

  RhpcBLASctl::omp_set_num_threads(1)

  beta = ifelse(i < nsims/2, .05, 0)

  Sigma = diag(c(5,1.4))
  Sigma[1,2] = cor.target * prod(sqrt(diag(Sigma)))
  Sigma[2,1] = Sigma[1,2]
  data = rmvnorm(p, c(0, 0), Sigma)
  chi = data[,1]
  eta = alpha + beta*data[,2]
  v.x = rgamma(p, 1,1) * 5
  v.y = rgamma(p, 1,1) * 5

  x = chi + sapply(v.x, function(v) rnorm(1, 0, sqrt(v)))
  y = eta + sapply(v.y, function(v) rnorm(1, 0, sqrt(v)))

  hobj = heivr(x, y, v.x, v.y)

  data.frame(i, beta, 
    p.pearson = cor.test(x,y)$p.value, 
    p.heivr = hobj$p.value)
  }, mc.cores=24)
df = do.call(rbind, df)

pr.pearson <- pr.curve( 
                scores.class0 = -log10(df$p.pearson)[df$beta!=0], 
                scores.class1 = -log10(df$p.pearson)[df$beta==0], 
                curve = TRUE,
                rand.compute=TRUE)


pr.heivr <- pr.curve( 
                scores.class0 = -log10(df$p.heivr)[df$beta!=0], 
                scores.class1 = -log10(df$p.heivr)[df$beta==0], 
                curve = TRUE,
                rand.compute=TRUE)
```

```{r plot.assoc, fig.height=4.5, fig.width=4, cache=FALSE}
plot(pr.pearson, rand.plot=TRUE, color="blue3")
plot(pr.heivr, rand.plot=TRUE, color="red3", add=TRUE)
```

```{r plot.null, cache=FALSE}
hist(df$p.pearson[df$beta==0])
hist(df$p.heivr[df$beta==0])
```

## SessionInfo
<details>
```{r sessionInfo}
sessionInfo()
```
</details>
