---
title: "Evalauting correlation between t-statistics"
subtitle: 'Sub-sampling data'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Decorrelate}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---


<!--- 

cd /Users/gabrielhoffman/workspace/repos/heivr_analysis

cd ~/work/heivr_analysis
ml git
R

system("git pull"); rmarkdown::render("corr_btw_tstats.Rmd");



https://hoffmg01.u.hpc.mssm.edu/work/heivr_analysis/corr_btw_tstats.html



--->

  


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  cache = TRUE,
  package.startup.message = FALSE,
  cache.lazy = FALSE)
```

```{r load.packages, cache=FALSE}
library(MASS)
library(ggplot2)
library(Rfast)
library(variancePartition)
library(tidyverse)
library(broom)
library(heivr)
library(BiocParallel)
library(deming)
library(mcr)
library(parallel)
library(PRROC)
```

```{r test}
heivr.boot.se = function(x, y, v.x, v.y, nboot=1000, tol=1e-4){

  stopifnot( length(x) == length(y))
  
  ## bootstrap out
  bs.out <- replicate(nboot, {
    i <- sample.int(length(x), length(x), replace=TRUE)
    heivr(x[i], y[i], v.x[i], v.y[i], tol=tol)$rho
  })
  sd(bs.out)
}
```



```{r sims.function, cache=FALSE}
run_simulation = function(nmax, ngenes, cor.target, nvalues, hsq, nreps=100, BPPARAM=SnowParam(4)){

  # simulate fixed covariate
  info = data.frame(x = rnorm(nmax))
  rownames(info) = paste0("s", 1:nmax)

  # simulate coefficients
  if( cor.target == 1 ){
    beta = rnorm(ngenes, 3)
    Beta = cbind(beta, beta)
  }else{
    # Sigma = diag(1,2)
    Sigma = diag(c(5,1.4))
    Sigma[1,2] = cor.target * prod(sqrt(diag(Sigma)))
    Sigma[2,1] = Sigma[1,2]
    Beta = rmvnorm(ngenes, c(1,-1.5), Sigma)
  }
  rownames(Beta) = paste0("gene_", 1:nrow(Beta))

  # Simulate gene expression
  geneExpr1 = t(sapply(Beta[,1], function(b){
    eta = info$x*b 

    # set cor(y, eta)^2 = hsq
    se = sqrt((1-hsq) / hsq * var(eta))
    eta + rnorm(nmax, 0, se)
    }))
  colnames(geneExpr1) = paste0("s", 1:nmax)

  geneExpr2 = t(sapply(Beta[,2], function(b){
    eta = info$x*b 

    # set cor(y, eta)^2 = hsq
    se = sqrt((1-hsq) / hsq * var(eta))
    eta + rnorm(nmax, 0, se)
    }))
  colnames(geneExpr2) = paste0("s", 1:nmax)

  grd = expand.grid(k = 1:nreps, N = nvalues)

  df = bplapply(apply(grd, 1, as.list), function(x, geneExpr1, geneExpr2, info){

    suppressPackageStartupMessages({
    library(heivr)
    library(variancePartition)})

    N = x$N

    # subset data, fit regression models, and extract results
    idx1 = sample.int(nmax, N, replace=FALSE)
    fit1 = dream(geneExpr1[,idx1], ~ x, info[idx1,,drop=FALSE], quiet=TRUE)
    fit1 = eBayes(fit1)
    tab1 = topTable(fit1, coef="x", number=Inf, sort.by='none')

    idx2 = sample.int(nmax, N, replace=FALSE)
    fit2 = dream(geneExpr2[,idx2], ~ x, info[idx2,,drop=FALSE], quiet=TRUE)
    fit2 = eBayes(fit2)
    tab2 = topTable(fit2, coef="x", number=Inf, sort.by='none')

    # merge and compute correlation between t-stats
    tab = merge(tab1, tab2, by="row.names")

    rm(fit1, tab1, fit2, tab2)

    # heivr - mom
    hobj.mom = with(tab, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2, (logFC.y/t.y)^2, method="mom", nboot=0 ))

    # heivr
    hobj = with(tab, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2,(logFC.y/t.y)^2, tol=1e-3))
    
    # covariance  
    data.frame( cor = with(tab, cor(logFC.x, logFC.y)),
                cor.mom = hobj.mom$rho,
                cor.heivr = hobj$rho,
                N = N)
  }, geneExpr1 = geneExpr1, geneExpr2 = geneExpr2, info = info,
    BPPARAM = BPPARAM)
  df = do.call(rbind, df)
  
  # combine results
  rbind(data.frame(Method = "heivr", 
                  cor = df$cor.heivr,  
                  N = df$N), 
        data.frame(Method = "MOM", 
                  cor = df$cor.mom, 
                  N = df$N), 
        data.frame(Method = "Pearson", 
                  cor = df$cor, 
                  N = df$N))
}
```

```{r run.sims}
# simulation parameters
nmax = 1000
ngenes = 1000 
cor.target = .8
nvalues = c(seq(50, 100, by=30), seq(130, 500, by=75), seq(575, nmax, by=150))
hsq = 0.6
  
df_param = expand.grid(hsq = c(.01, 0.05, .2), 
            cor.target = c(0, 0.2, 0.5, 0.8, 1))


df_param = expand.grid(hsq = c(.01, .2), 
            cor.target = c(0.2, 0.8))


# df_param = expand.grid(hsq = .02, cor.target = .8)
 
df = lapply( 1:nrow(df_param), function(i){
  message(i, ':')

  df = run_simulation(nmax, ngenes, cor.target = df_param$cor.target[i], nvalues, hsq = df_param$hsq[i], nreps=10, BPPARAM=SnowParam(4, progressbar=TRUE))
  df$cor.target = df_param$cor.target[i]
  df$hsq = df_param$hsq[i]
  df 
})  
df = do.call(rbind, df)
```




rmarkdown::render("corr_btw_tstats.Rmd");





```{r plot1, cache=FALSE, fig.height=12, fig.width=12}
col = c(heivr = "red3", Pearson = "blue3", MOM="green3")

df2 = df %>% 
    group_by(Method, cor.target, hsq, N) %>%
    summarize(rho.mean = mean(cor), rho.se = sd(cor))

df2$offset = sapply(df2$Method, function(x) 
                switch(x, heivr = -3, Pearson=0, MOM=3))

ggplot(df2, aes(N + offset, pmax(0, pmin(1, rho.mean)), col=Method)) +
  geom_hline(aes(yintercept=cor.target), linetype="dashed", color="black") +
  geom_errorbar(aes(ymin = pmax(0,rho.mean - 1.96*rho.se), ymax = pmin(1, rho.mean + 1.96*rho.se)), width=0) +
  geom_point() +
  theme_classic() +
  theme(aspect.ratio=1) +
  scale_y_continuous(limits=c(-1,1), expand=c(0,0.03)) +
  scale_x_continuous(limits=c(0,nmax), expand=c(0,0.03)) +
  ylab("Estimated correlation") +
  xlab("Sample size") +
  scale_color_manual(values = col) + 
  facet_grid(cor.target ~ hsq)
```

Simulate two datasets with `r nmax` samples and `r format(ngenes, scientific=FALSE, big.mark=',')` genes where the logFC between datasets have a correlation of `r unique(df$cor.target)`.  Perform analysis on random subsets of the data, and evaluate the correlation between the estimated t-statistics.  For each gene, the variable of interest explains `r 100*unique(df$hsq)`% of the variance.

Method of moments error is simple and fast, but is not bounded between 0 and 1.  This is mostly a problem when measurement error is large.  Also, the MOM estimater has larger sampling variance than the MLE does. 

Cite Fuller (1987) on measurement error and MOM.  Deming proposes way to estimate coefficients, but not correlation.

Attentuation bias, or regression dilution. Originally recognized by Spearman (1904) [The proof and measurement of association between two things]

Suprizingly, the convergence rate of Pearson depends on the target correlation value

Convergance time is directly related to measurement error

Prefer MLE since it generally produces lower standard error, and gives a likelihood ratio test to test for association.



show iterations determiend by meansurement error
For small error, convergnces to Pearson corr
test of association

```{r time.vs.noise}
p = 10000
Sigma = matrix(c(10, 3, 3, 4),2,2)
data = rmvnorm(p, c(0, 0), Sigma)
x = data[,1]
y = data[,2]
v = rgamma(p,10, 10)

df = lapply(seq(-3, 3, length.out=20), function(value){
  message(value)
  res = system.time(hobj <- heivr(x, y, v*10^value, v*10^value, tol=1e-2))
  data.frame(value, 
    niter = hobj$niter, 
    logLik = hobj$logLik, 
    time = res[3])
  })
df = do.call(rbind, df)
```


```{r plot.time.vs.noise}
fig1 = ggplot(df, aes(value, niter)) +
  geom_point() +
  theme_classic() +
  theme(aspect.ratio=1) +
  xlab(bquote(log[10]~noise~variance)) +
  ylab("# iterations") +
  scale_y_log10()

fig2 = ggplot(df, aes(value, time)) +
  geom_point() +
  theme_classic() +
  theme(aspect.ratio=1) +
  xlab(bquote(log[10]~noise~variance)) +
  ylab("Run time (seconds)") 

cowplot::plot_grid(fig1, fig2)  
```

# Test of association
heivr only out performs Pearson correlation when there is heteroskedastic noise
```{r assoc}
cor.target = .8

p = 1000
alpha = .08

nsims = 2000

df = mclapply(1:nsims, function(i){

  message(i)
  beta = ifelse(i < nsims/2, .05, 0)

  Sigma = diag(c(5,1.4))
  Sigma[1,2] = cor.target * prod(sqrt(diag(Sigma)))
  Sigma[2,1] = Sigma[1,2]
  data = rmvnorm(p, c(0, 0), Sigma)
  chi = data[,1]
  eta = alpha + beta*data[,2]
  v.x = rgamma(p, 1,1)
  v.y = rgamma(p, 1,1)

  x = chi + sapply(v.x, function(v) rnorm(1, 0, sqrt(v)))
  y = eta + sapply(v.y, function(v) rnorm(1, 0, sqrt(v)))

  hobj = heivr(x, y, v.x, v.y, tol=1e-3, LRT=TRUE)

  data.frame(i, beta, 
    p.pearson = cor.test(x,y)$p.value, 
    p.heivr = hobj$p.value)
  }, mc.cores=4)
df = do.call(rbind, df)

pr.pearson <- pr.curve( 
                scores.class0 = -log10(df$p.pearson)[df$beta!=0], 
                scores.class1 = -log10(df$p.pearson)[df$beta==0], 
                curve = TRUE,
                rand.compute=TRUE)


pr.heivr <- pr.curve( 
                scores.class0 = -log10(df$p.heivr)[df$beta!=0], 
                scores.class1 = -log10(df$p.heivr)[df$beta==0], 
                curve = TRUE,
                rand.compute=TRUE)
```

```{r plot.assoc, fig.height=4.5, fig.width=4, cache=FALSE}
plot(pr.pearson, rand.plot=TRUE, color="blue3")
plot(pr.heivr, rand.plot=TRUE, color="red3", add=TRUE)
```

```{r plot.null, cache=FALSE}
hist(df$p.pearson[df$beta==0])
hist(df$p.heivr[df$beta==0])
```







