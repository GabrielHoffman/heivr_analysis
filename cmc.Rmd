---
title: "Compare CommonMind Consortium signatures"
subtitle: 'hevir on biological data'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Compare CommonMind Consortium signatures}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---


<!---

cd /Users/gabrielhoffman/workspace/repos/heivr_analysis

cd ~/work/heivr_analysis

# rm -rf cmc_cache

ml git
ml gcc/11.2.0
R

system("git pull"); 
library(synapser, lib.loc="~/.Rlib/R_420/")
rmarkdown::render("cmc.Rmd");

https://hoffmg01.u.hpc.mssm.edu/work/heivr_analysis/cmc.html

scp sklar1:~/www/work/heivr_analysis/cmc.html .

--->



```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  cache = TRUE,
  package.startup.message = FALSE,
  cache.lazy = FALSE)
```

```{r load}
library(heivr)
library(variancePartition)
library(parallel)
library(broom)
library(tidyverse)
```

```{r synapser, cache=TRUE}
library(synapser, lib.loc="~/.Rlib/R_420/")
synLogin()

# Load data and results
METADATA = readRDS(synGet('syn24180850')$path)
vobj.lst = readRDS(synGet('syn24180852')$path)
fitList = readRDS(synGet('syn24180854')$path)
```

```{r analysis}
# run top table for each cohort
coefTest = c('DxSCZ', 'Reported_GenderMale', 'ageOfDeath')

hobjList = lapply( coefTest, function(coef){
  tabList = lapply( fitList, function(fit){
  	topTable(fit, coef=coef, number=Inf)
  })

  # merge results
  df = merge(tabList[[1]], tabList[[2]], by="row.names")

  # MLE
  hobj = with(df, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2, (logFC.y/t.y)^2))

  hobj 
})
names(hobjList) = coefTest
```

```{r plot, fig.width=14}
par(mfrow=c(1,3))
for(coef in names(hobjList)){
  hobj = hobjList[[coef]]
  lim = max(abs(c(hobj$x, hobj$y)))
  lim = c(-lim, lim)

  plot(hobj, xlab="logFC (MSSM-Penn-Pitt)", ylab="logFC (NIMH-HBCC)", main=coef, xlim=lim, ylim=lim)
  abline(0,1)
  abline(h=0, lty=3)
  abline(v=0, lty=3)  
} 
```


# Ramp up analysis
Subsample subjects and get empirical standard errors.  Need to do this for simulation instead of theoretical se.

```{r de.rampup, cache=FALSE}
get_rho_rampup = function( coef, fractions=seq(.2, 1, length.out=3), nreps=10, BPPARAM = SnowParam(4, progressbar=TRUE) ){

  form.lst = list(
    `MSSM-Penn-Pitt`  = ~ Dx + Reported_Gender + RIN +scale(IntronicRate) + scale(IntragenicRate) + scale(IntergenicRate) + scale(rRNARate) + Institution*(ageOfDeath + cellFrac_ilr_1 + cellFrac_ilr_2 + cellFrac_ilr_3),
    `NIMH-HBCC`       = ~ Dx + Reported_Gender + RIN + scale(IntronicRate) + scale(IntragenicRate) + scale(IntergenicRate) + scale(rRNARate) + ageOfDeath + cellFrac_ilr_1 + cellFrac_ilr_2 + cellFrac_ilr_3)

  res = bplapply(1:nreps, function(k, vobj.lst, METADATA, fractions){
    suppressPackageStartupMessages({
    library(broom)
    library(tidyverse)
    library(heivr)
    library(RhpcBLASctl)
    library(dreamlet)
    library(variancePartition)})
    omp_set_num_threads(1)

    res = lapply( fractions, function(frac){

      fit_marginal.lst = lapply( vobj.lst, function(vobj){
        i = match(colnames(vobj), rownames(METADATA))
        info = METADATA[i,]

        idx = sample.int( ncol(vobj), ncol(vobj)*frac)

        info.sub = droplevels(info[idx,])
        form_mod = form.lst[[info$Cohort[1]]]

        tryCatch({
          fit = dream(vobj[,idx], form_mod, info.sub, quiet=TRUE)  
          fit = eBayes( fit )
        }, error = function(e) fit = NULL, 
        warning = function(w) fit = NULL)
        })
      names(fit_marginal.lst) = names(vobj.lst)

      if( any(sapply(fit_marginal.lst, is.null)) ){
        df = data.frame( fraction = frac, 
                    k = k,
                    rho.Pearson = NA,
                    rho.heivr = NA,
                    rho.mom = NA)
        return(df)
      }

      # run top table for each cohort
      tabList = lapply( fit_marginal.lst, function(fit){
        topTable(fit, coef=coef, number=Inf)
      })

      # merge results
      df = merge(tabList[[1]], tabList[[2]], by="row.names")

      # Pearson
      fit.Pearson = with(df, cor.test(logFC.x, logFC.y)) %>% tidy %>% mutate(se = sqrt((1 - estimate^2)/parameter))

      # MLE
      hobj = with(df, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2, (logFC.y/t.y)^2, LRT=FALSE))

      # MOM
      hobj.mom = with(df, heivr(logFC.x, logFC.y, (logFC.x/t.x)^2, (logFC.y/t.y)^2, method="mom", nboot=0))

      data.frame( fraction = frac, 
                  k = k,
                  rho.Pearson = fit.Pearson$estimate,
                  rho.heivr = hobj$rho,
                  rho.mom = hobj.mom$rho)
    })
    do.call(rbind, res)
  }, vobj.lst=vobj.lst, METADATA=METADATA, fractions=fractions, BPPARAM=BPPARAM)
  res = do.call(rbind, res)

  message(dim(res))
  # combine results
  res = rbind( with(res, data.frame( 
                      Method = "heivr",
                      fraction = fractions, 
                      rho = rho.heivr)),
                with(res, data.frame( 
                      Method = "MOM",
                      fraction = fractions, 
                      rho = rho.mom)),
                with(res, data.frame( 
                      Method = "Pearson",
                      fraction = fractions, 
                      rho = rho.Pearson)) )

  res$Method = factor(res$Method, c("heivr", "MOM", "Pearson"))
  res$coef = coef

  res
}
```



```{r run_ramp}
# ramp up analysis
coefTest = c('DxSCZ', 'Reported_GenderMale', 'ageOfDeath')
frac = c(seq(.03, .13, length.out=10), seq(.15, 1, length.out=20))

df.ramp = lapply(coefTest, function(coef){
  message(coef)
  get_rho_rampup(coef, frac, nreps=500, BPPARAM = SnowParam(6))
  })
df.ramp = do.call(rbind, df.ramp)
```

Note slight x-axis offset was added to plot so confidence intervals would be visible
```{r rampup.plot.SCZ, cache=FALSE, fig.width=10, fig.height=5}
res2 = df.ramp %>%
  filter(!is.na(rho)) %>%
  group_by(coef, Method, fraction) %>%
  summarize( rho.mean = mean(rho), rho.se = sd(rho), rho.sem = sd(rho) / sqrt(length(rho)), n = length(rho))

res2$offset = sapply(as.character(res2$Method), function(x) 
                switch(x, Pearson=-0.01, heivr = 0, MOM=0.01))

res2$coef = factor(res2$coef, coefTest)

res2 %>%
  ggplot(aes(fraction + offset, rho.mean, color=Method)) +
    geom_point(size=.3) + 
    geom_line() + 
    geom_ribbon(aes(ymin = pmax(0,rho.mean - 1.96*rho.sem), ymax = pmin(1, rho.mean + 1.96*rho.sem), fill=Method), linetype=0, alpha=.4) +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_x_continuous(limits=c(0,1.02), expand=c(0,0), 
      labels=c('0', '0.25', '0.50', '0.75', '1')) +
    scale_y_continuous(limits=c(0,1.02), expand=c(0,0)) +
    xlab("Fraction of subjects included from each study") +
    ylab("Estimated correlation") +
    scale_color_manual(values=c("red3", "green3", "blue3")) +
    facet_wrap(~coef)
```


## Predict required sample size
```{r asymp}
# https://www.r-bloggers.com/2020/02/a-collection-of-self-starters-for-nonlinear-regression-in-r/

# Compute number of samples that gives plateau 
# assuming that Pearson correlation versus sample size 
# satisfies this functional form  
asymptotic_x = function(x, y, plateau, target.error = 0.05){

  # fit asymptotic model
  fit = nls( y ~ plateau - plateau * exp (- c * x), 
    start=list( c=0), 
    control = nls.control(maxiter=1000))

  # predictions from model
  x.values = seq(1, 100, length.out=10000)
  y.predict = plateau - plateau * exp (- coef(fit)['c'] * x.values)

  # plot(x.values, y.predict, ylim=c(0, plateau * 1.1))
  # abline(h=plateau)

  # relative error
  relative.error = abs(y.predict - plateau) / plateau

  # return input with target relative error
  i = min(which( relative.error < target.error))
  list(nhat = x.values[i], coef.value = coef(fit)['c'])
}

res_plateau = lapply(levels(res2$coef), function(coefValues){

  data = res2 %>%
    filter(coef == coefValues, Method == "Pearson") 

  plateau = res2 %>%
    filter(coef == coefValues, Method == "heivr") %>%
    summarize(plateau=max(rho.mean)) %>%
    unlist

  df = asymptotic_x( data$fraction, data$rho.mean, plateau)

  data.frame(coef = coefValues, plateau = plateau, df)
})
res_plateau = do.call(rbind, res_plateau)
res_plateau$coef = factor(res_plateau$coef, levels(res2$coef))

ymax = max(res_plateau$nhat)*1.03
ggplot(res_plateau, aes(coef, nhat, fill=coef)) +
  geom_bar(stat="identity") +
  theme_classic() +
  theme(aspect.ratio=1, legend.position="none") +
  scale_y_continuous(lim=c(0, ymax), expand=c(0,0)) +
  geom_hline(yintercept=1, linetype="dashed") +
  xlab("Phenotype tested") +
  ylab("Sample size factor to reach plateau")
```

### Example 
```{}
df = res_plateau %>% 
  filter(coef == "DxSCZ")

x.values = seq(0, 100, length.out=10000)
y.predict = df$plateau - df$plateau * exp (- df$coef.value * x.values)
data_predict = data.frame(x = x.values, y= y.predict)

res2 %>%
  filter(coef == "DxSCZ") %>%
  ggplot(aes(fraction + offset, rho.mean, color=Method)) +
    geom_point(size=.3) + 
    geom_line() + 
    geom_ribbon(aes(ymin = pmax(0,rho.mean - 1.96*rho.sem), ymax = pmin(1, rho.mean + 1.96*rho.sem), fill=Method), linetype=0, alpha=.4) +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_x_continuous(limits=c(0,df$nhat*1.05), expand=c(0,0)) +
    scale_y_continuous(limits=c(0,1.02), expand=c(0,0)) +
    xlab("Fraction of subjects included from each study") +
    ylab("Estimated correlation") +
    scale_color_manual(values=c("red3", "green3", "blue3")) +
    # facet_wrap(~coef) +
    geom_line(data=data_predict, aes(x, y), color="black") +
    geom_hline(yintercept = df$plateau, linetype="dashed")
```





## SessionInfo
<details>
```{r sessionInfo}
sessionInfo()
```
</details>



